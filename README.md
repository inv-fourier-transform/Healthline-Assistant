# Healthline Assistant: RAG-based chatbot for articles ğŸ©ºâš¡ï¸

A fast, grounded, Healthlineâ€‘only chatbot that builds local embeddings from provided URLs and answers strictly from those sources.

---

## ğŸ“– Description

### ğŸ”¹ What it does  
Builds a local vectorstore from userâ€‘selected Healthline articles, then answers questions strictly using content retrieved from those sources.

### ğŸ”¹ What problem it solves  
Eliminates manual copyâ€‘paste and unreliable, nonâ€‘grounded answers by constraining the model to only the supplied Healthline context.

### ğŸ”¹ Motivation  
Inspired by a conversation with a doctor neighbour who found it timeâ€‘consuming to manually copy links from Pocket into ChatGPT for summarization; this RAG solution automates ingestion, retrieval, and grounded answering exclusively from Healthline articles.

---

## ğŸ“‚ Folder Structure

```bash
Healthcare_Assistant/
â”œâ”€ core/                     # Backend (ingestion, chunking, embeddings, vectorstore, retrieval, LLM, QA)
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ config_loader.py       # Loads config.yaml + .env and resolves paths (e.g., persist directory)
â”‚  â”œâ”€ loader.py              # Robust URL loader for Healthline content
â”‚  â”œâ”€ chunker.py             # Recursive chunk splitter with overlap
â”‚  â”œâ”€ embeddings.py          # Embedding factory (HF/SentenceTransformer + trust_remote_code support)
â”‚  â”œâ”€ vector_store.py        # Chroma lifecycle (reset persist dir; create store)
â”‚  â”œâ”€ indexer.py             # Full rebuild on new URLs; writes collection fingerprint + sources manifest
â”‚  â”œâ”€ retrieval.py           # Vectorstore rehydration + general/per-source retrievers
â”‚  â”œâ”€ llm.py                 # Chat model factory (Groq or configured LLM)
â”‚  â””â”€ qa.py                  # Strictly grounded QA + per-source summarization (no external citations)
â”‚
â”œâ”€ frontend/
â”‚  â””â”€ ui_interface.py        # Streamlit UI (dark mode, 10 URL slots, validation, grounded answers)
â”‚
â”œâ”€ config/
â”‚  â”œâ”€ config.yaml            # App configuration (models, chunking, retrieval, paths)
â”‚  â””â”€ .env                   # Secrets and runtime env (e.g., GROQ_API_KEY, EMBEDDING_MODEL)
â”‚
â”œâ”€ main.py                   # CLI runner: index URLs and ask questions (or summarize per article)
â”œâ”€ requirements.txt          # Python dependencies
â””â”€ README.md                 # Project documentation
```

---

## âš™ï¸ Installation Steps

> âš ï¸ **Note:** You must create a `.env` file inside the `config/` folder and provide the following variables:  
> - `GROQ_API_KEY`  
> - `CHROMA_DIR`  
> - `GROQ_MODEL`  
> - `EMBEDDING_MODEL`  


```bash
# 1) Python and virtual environment
python -V               # recommend 3.10+
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS / Linux
source .venv/bin/activate

# 2) Install dependencies
pip install --upgrade pip
pip install -r requirements.txt

# 3) Configure environment (copy and edit as needed)
#   - config/.env must define at least:
#     GROQ_API_KEY=<your_key>
#     EMBEDDING_MODEL="Alibaba-NLP/gte-base-en-v1.5"  # or another supported model
#     # Optional override: CHROMA_DIR=vector_resources/vectorstore

# 4) Verify config
#   - config/config.yaml is present
#   - CHROMA persist directory is resolved under config/ by default
```

**Notes:**  
- The embedding loader supports models that require custom code (`trust_remote_code=True`) and normalizes embeddings for cosine search when appropriate.  
- The vectorstore path is resolved relative to the `config/` folder by default and can be overridden via `CHROMA_DIR` in `.env` (relative paths recommended).  

---

## â–¶ï¸ Execution Steps

### CLI (backend only)

```bash
# From the project root
python main.py
```

**Follow prompts:**  
- Paste 1â€“10 Healthline URLs  
- Wait for indexing: old embeddings are cleared; new ones are built  
- Enter a query (answers are strictly from the indexed sources)  
- To summarize per article: phrase query like *"summarize them separately"*  

### Streamlit UI

```bash
# From the project root
streamlit run frontend/ui_interface.py
```

**In the app:**  
- Paste up to 10 Healthline URLs (fixed rows)  
- Click *"Validate & Submit URLs"* to rebuild embeddings (resets vectorstore)  
- Enter a query and *"Submit query"* for a grounded answer + Healthline source list  

âœ… **Behavior guarantees:**  
- *"Validate & Submit URLs"* always clears the existing vectorstore and rebuilds embeddings from scratch.  
- Answers are strictly grounded; if nothing relevant is retrieved, the app returns the exact fallback message.  

---

## ğŸ” URL Validation Steps

### Allowed prefixes
- `healthline.com`  
- `www.healthline.com`  
- `https://www.healthline.com`  

### Canonicalization
- Forces `https` scheme and `www.healthline.com` netloc  
- Lowercases the path  
- Removes query/fragment  
- Collapses duplicate slashes  
- Trims trailing slash (except root)  

### Deduplication
Detects duplicates across formats using canonical form (e.g., `healthline.com/...`, `www.healthline.com/...`, and `https://www.healthline.com/...` all resolve to one).

### Limits
- 1â€“10 URLs per session; empty rows are ignored.  
- Only validated, canonical Healthline URLs proceed to loading and embedding.  

---

## ğŸ› ï¸ Technologies Used

- âœ… Python 3.10+  
- âœ… Streamlit (frontend UI)  
- âœ… LangChain (chains, prompts, retrievers)  
- âœ… ChromaDB (local vectorstore persistence)  
- âœ… Sentence-Transformers / Hugging Face (embeddings, trust_remote_code support)  
- âœ… Groq (LLM API integration) â€” can also run locally via Ollama  
- âœ… Unstructured URL loader (robust web article parsing)  
- âœ… python-dotenv, PyYAML (config/env management)  

---

## ğŸš€ Roadmap & Future Updates

- ğŸ“œ **Detailed moduleâ€‘wise logs**: Structured logging for ingestion, chunking, embedding, retrieval, and answering to simplify audits and error tracing.  
- ğŸ”— **Pocket integration**: Oneâ€‘click import of saved Healthline links from Pocket.  
- â˜ï¸ **Cloud deployment**: Dockerize and deploy on a managed platform.  
- ğŸ§ª **Model experiments**: Test other embeddings and LLMs for groundedness and evaluate multiâ€‘query retrieval for complex questions.  

---

## ğŸ™ Credits and Acknowledgements

- Healthline articles for highâ€‘quality, clinicianâ€‘reviewed content used as the knowledge base.  
- Openâ€‘source maintainers across the LangChain, ChromaDB, Hugging Face, Streamlit, and Sentenceâ€‘Transformers ecosystems.  

---

## âš ï¸ Disclaimer

â€œAll rights to the content in the provided URLs belong solely to Healthline Media LLC.â€  

---

## ğŸ“Œ Quick Tips

- Reâ€‘indexing resets prior embeddings; keep distinct sessions per topic for focused retrieval.  
- Use precise, articleâ€‘aligned queries; for multiâ€‘article tasks, the system can summarize each article separately.  
- If a fact isnâ€™t in the supplied Healthline sources, the assistant will return the exact fallback rather than hallucinate.  
